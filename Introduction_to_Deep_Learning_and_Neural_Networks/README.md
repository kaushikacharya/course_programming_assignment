# Introduction to Deep Learning & Neural Networks

## About

This repository contains

- [Course notes](#course-contents)
- [Assignments](#assignments)
- Additional resources (collected for better understanding of the concepts)

## Course Information

- Course author(s): [AI Summer](https://theaisummer.com/introduction-to-deep-learning-course/)
- [Course Website](https://www.educative.io/courses/intro-deep-learning)

## Course Contents

- [Chapter 0: Learn Deep Learning](./notes/Chapter_0.md)
- [Chapter 1: Neural Networks](./notes/Chapter_1.md)
- [Chapter 2: Training Neural Networks](./notes/Chapter_2.md)
- [Chapter 3: Convolutional Neural Networks](./notes/Chapter_3.md)
- [Chapter 4: Recurrent Neural Networks](./notes/Chapter_4.md)
- [Chapter 5: Autoencoders](./notes/Chapter_5.md)
- [Chapter 6: Generative Adversarial Networks](./notes/Chapter_6.md)
- [Chapter 7: Attention and Transformers](./notes/Chapter_7.md)
- [Chapter 8: Graph Neural Networks](./notes/Chapter_8.md)
- [Conclusion](./notes/Conclusion.md)

## Assignments

  |Chapter|         Assignment        |   Description   |
  |-------|---------------------------|-----------------|
  |#1|[Train linear classifier](./notes/Chapter_1.md#summing-up-the-training-scheme)|Train a linear classifier with dummy input values.|
  |#2|[Train a Neural Network](./notes/Chapter_2.md#help)|Train a neural network to classify CIFAR10 images into one of the 10 classes.|
  |#3|[Build and Train CNN](./notes/Chapter_3.md#build-a-convolutional-network)|Build and train CNN on CIFAR dataset. This assignment is a follow-up of previous assignment (Chapter #2). Here feedforward network is replaced by CNN.|
  |#3|[Batch Normalization](./notes/Chapter_3.md#batch-normalization-implementation)|Batch normalization function|
  |#3|[Skip Connection](./notes/Chapter_3.md#resnet-skip-connections-via-addition)|ResNet skip connection class|
  |#4|[LSTM cell](./notes/Chapter_4.md#simplication-of-lstm-equations)|Develop an LSTM cell from scratch.|
  |#4|RNN|RNN|
  |#5|[Autoencoder](./notes/Chapter_5.md#exercise)|Filter size computed from the equation for number of parameters.|
  |#5|[ELBO](./notes/Chapter_5.md#elbo-implementation)|Evidence lower bound (ELBO)|
  |#5|[Reparameterization trick](./notes/Chapter_5.md#reparameterization-trick-exercise)|Reparameterization trick|
  |#6|[GAN](./notes/Chapter_6.md#develop-a-gan-with-pytorch)|Generative Adversarial Network|
  |#7|[Transformer Encoder](./notes/Chapter_7.md#build-a-transformer-encoder)|A simple transformer encoder|
  |#8|[Graph Laplacian](./notes/Chapter_8.md#the-graph-laplacian)|Graph Laplacian|
  |#8|[Spectral Image Segmentation](./notes/Chapter_8.md#spectral-image-segmentation-with-graph-laplacian)|Spectral Image Segmentation with Graph Laplacian|
  |#8|[Chebyshev approximation](./notes/Chapter_8.md#illustration-of-the-general-graph-convolution-method)|Chebyshev approximation for the Laplacian powers|
  |#8|[GCN](./notes/Chapter_8.md#assignment)|1-hop Graph Convolutional Network|
  *****

## Certificate

- [Course completion certificate](./certificate/introduction_to_deep_learning_and_neural_networks_educative.pdf)
- Issued on August 2023

## Related Repositories

- [Deep Learning PyTorch Fundamentals](https://github.com/kaushikacharya/course_programming_assignment/tree/master/Deep_Learning_Pytorch_Fundamentals_Educative)
  - Explains the basics of PyTorch model training using a simple regression and a classification problem.
  - The steps involved in the training process are better explained in this course.

- [Natural Language Processing with Deep Learning (CS224n)](https://github.com/kaushikacharya/Natural_Language_Processing_with_Deep_Learning_CS224n)
  - Stanford University course by Prof. Christopher Manning
  - The repository contains my assignment solutions.
