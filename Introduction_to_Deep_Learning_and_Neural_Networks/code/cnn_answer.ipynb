{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "natural-springer",
   "metadata": {},
   "source": [
    "# Build and train a Convolutional Neural Network\n",
    "\n",
    "The below code should seem familiar to you as it's very similar with the one we used when training a feedforward network. The difference is that this time we have a CNN. As always, you can find a sample solution in the last cell.\n",
    "\n",
    "Once again, we will import all the necessary libraries along with our pet images dataset. The images will be transformed to tensors and will be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "#add CIFAR10 data in the environment\n",
    "sys.path.append(cwd + '/../cifar10')\n",
    "\n",
    "#Numpy is linear algebra lbrary\n",
    "import numpy as np\n",
    "# Matplotlib is a visualizations library \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import utils\n",
    "from torchvision import transforms\n",
    "#CIFAR10 is a custom Dataloader that loads a subset ofthe data from a local folder\n",
    "from Cifar10Dataloader import CIFAR10\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "def show_image(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    #convert the images to tensor and normalized them\n",
    "    transform = transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    trainset = CIFAR10(root='../cifar10',  transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=False, num_workers=1)\n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-softball",
   "metadata": {},
   "source": [
    "## Define a CNN\n",
    "\n",
    "Here you will come into play. Try to define the necessary layers and build the forward pass of our model. Remember that the model's structure is:\n",
    "\n",
    "\n",
    "- A conv layer with 3 channels as input, 6 channels as output, and a 5x5 kernel\n",
    "- A 2x2 max-pooling layer\n",
    "- A conv layer with 6 channels as input, 16 channels as output, and a 5x5 kernel\n",
    "- A linear layer with 16*5*5 nodes\n",
    "- A linear layer with 120 nodes\n",
    "- A linear layer with 84 nodes\n",
    "- A linear layer with 10 nodes\n",
    "\n",
    "The trickiest part when building CNNs is to find the correct dimensions for each layer. If you managed to use the correct arguments in the `Conv2d` layers, you will be ok. Also play close attention to first `Linear` layer. How will you be able to pass the feature map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. DEFINE THE CNN HERE\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.linear1 = nn.Linear(in_features=1600, out_features=1655)\n",
    "        self.linear2 = nn.Linear(in_features=1655, out_features=120)\n",
    "        self.linear3 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.linear4 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"x.shape: {x.shape}\")\n",
    "        h1 = torch.relu(self.cnn1(x))\n",
    "        # print(f\"h1.shape: {h1.shape}\")\n",
    "        h2 = self.pool1(h1)\n",
    "        # print(f\"h2.shape: {h2.shape}\")\n",
    "        h3 = torch.relu(self.cnn2(h2))\n",
    "        # print(f\"h3.shape: {h3.shape}\")\n",
    "        # Now flatten image tensor\n",
    "        h3 = h3.view(-1, h3.shape[-3]*h3.shape[-2]*h3.shape[-1])\n",
    "        h4 = torch.relu(self.linear1(h3))\n",
    "        # print(f\"h4.shape: {h4.shape}\")\n",
    "        h5 = torch.relu(self.linear2(h4))\n",
    "        # print(f\"h5.shape: {h5.shape}\")\n",
    "        h6 = torch.relu(self.linear3(h5))\n",
    "        # print(f\"h6.shape: {h6.shape}\")\n",
    "        o = torch.sigmoid(self.linear4(h6))\n",
    "        # print(f\"o.shape: {o.shape}\")\n",
    "        return o\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unknown-mountain",
   "metadata": {},
   "source": [
    "## Train a CNN\n",
    "\n",
    "Now that you have the model, let's build the training loop and execute a few epochs. Here you will have to :\n",
    "\n",
    "- unwrap the input and labels\n",
    "- develop the forward and backward pass\n",
    "- print the loss every 2000 mini-batches (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. TRAIN THE MODEL HERE\n",
    "def train(model, training_data):\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=0.001, momentum=0.9)\n",
    "    running_loss = 0\n",
    "    n_mini_batch = 0\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(training_data, 0):\n",
    "            # get the inputs; cifar10 is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # compute gadients\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "           \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            n_mini_batch += 1\n",
    "            # print every 500 mini-batches\n",
    "            if i % 500 == 499:\n",
    "                print(f\"Epoch: {epoch+1} :: i: {i+1} :: loss: {running_loss/n_mini_batch}\")\n",
    "                # reset the variables\n",
    "                running_loss = 0\n",
    "                n_mini_batch = 0\n",
    "            \n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    dataiter = iter(load_data())\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # print images\n",
    "    show_image(utils.make_grid(images))\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    \n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    training_data = load_data()\n",
    "\n",
    "    model = CNN()\n",
    "\n",
    "    train(model, training_data)\n",
    "    \n",
    "    evaluate(model)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-survival",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. DEFINE THE CNN \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "#2. TRAIN THE MODEL \n",
    "def train(model, training_data):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(training_data, 0):\n",
    "            # get the inputs; cifar10 is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
