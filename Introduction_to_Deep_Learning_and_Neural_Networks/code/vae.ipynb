{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "charged-onion",
   "metadata": {},
   "source": [
    "# Build a Convolutional VAE and train it on Cifar10\n",
    "\n",
    "As we already mentioned during the lesson, here you are on your own. You will have to build everything from scratch. Your goal is to build a convolutional VAE of your own structure and train it on CIFAR10. Hyperparameters, optimizers, losses are also your own choice. \n",
    "\n",
    "Of course you can and should borrow stuff from the lessons and previous Jupyter notebooks.This is especially true for the data loading functionalities. You should use our custom CIFAR10 dataloader, as we did in the previous exercises.\n",
    "\n",
    "As always, feel free to advice the Pytorch documentation (links in the Appendix). Please make sure to have a working code before you leave. Good luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behind-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb94908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c584445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cloudy-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out for local run. This cell is required for executing the notebook in the course website's environment.\n",
    "# import os\n",
    "# import sys\n",
    "# cwd = os.getcwd()\n",
    "#add CIFAR10 data in the environment\n",
    "# sys.path.append(cwd + '/../cifar10') \n",
    "# from Cifar10Dataloader import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86bf15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advance-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #convert the images to tensor and normalized them\n",
    "    transform = transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    trainset = CIFAR10(root='~/data/cifar10',  download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=False, num_workers=1)\n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pointed-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.features =16\n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=3072, out_features=128)\n",
    "        self.enc2 = nn.Linear(in_features=128, out_features=self.features * 2)\n",
    "\n",
    "        # decoder\n",
    "        self.dec1 = nn.Linear(in_features=self.features, out_features=128)\n",
    "        self.dec2 = nn.Linear(in_features=128, out_features=3072)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = self.enc2(x).view(-1, 2, self.features)\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :]  # the first feature values as mean\n",
    "        log_var = x[:, 1, :]  # the other feature values as variance\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(z))\n",
    "        # reconstruction = torch.sigmoid(self.dec2(x))\n",
    "        reconstruction = self.dec2(x)\n",
    "        return reconstruction, mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)  # standard deviation\n",
    "        eps = torch.randn_like(std)  # generate sample of the same size\n",
    "        sample = mu + (eps * std)  # sampling as if coming from the input space\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082db872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(recon_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param recon_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    RL = recon_loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return RL + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db82b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,training_data):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(training_data, 0):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            # print(f\"min(inputs): {torch.min(input=inputs)} :: max(inputs): {torch.max(input=inputs)}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu, logvar = model(inputs)\n",
    "            # print(f\"min(reconstruction): {torch.min(input=reconstruction)} :: max(reconstruction): {torch.max(input=reconstruction)}\")\n",
    "            recon_loss = criterion(reconstruction, inputs)\n",
    "            loss = final_loss(recon_loss, mu, logvar)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 500 == 499:  # print every 500 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 500))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    PATH = '../output/cifar_net.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d9ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    trainloader = load_data()\n",
    "    model = VAE()\n",
    "    train(model=model, training_data=trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f34bfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1,   500] loss: 3729.379\n",
      "[1,  1000] loss: 2751.245\n",
      "[1,  1500] loss: 2558.947\n",
      "[1,  2000] loss: 2408.045\n",
      "[1,  2500] loss: 2369.778\n",
      "[1,  3000] loss: 2319.809\n",
      "[1,  3500] loss: 2316.240\n",
      "[1,  4000] loss: 2320.323\n",
      "[1,  4500] loss: 2324.318\n",
      "[1,  5000] loss: 2287.615\n",
      "[1,  5500] loss: 2266.271\n",
      "[1,  6000] loss: 2265.530\n",
      "[1,  6500] loss: 2270.950\n",
      "[1,  7000] loss: 2244.749\n",
      "[1,  7500] loss: 2301.104\n",
      "[1,  8000] loss: 2267.449\n",
      "[1,  8500] loss: 2182.348\n",
      "[1,  9000] loss: 2211.504\n",
      "[1,  9500] loss: 2279.092\n",
      "[1, 10000] loss: 2169.204\n",
      "[1, 10500] loss: 2218.209\n",
      "[1, 11000] loss: 2207.201\n",
      "[1, 11500] loss: 2198.290\n",
      "[1, 12000] loss: 2174.549\n",
      "[1, 12500] loss: 2206.873\n",
      "[2,   500] loss: 2213.193\n",
      "[2,  1000] loss: 2211.459\n",
      "[2,  1500] loss: 2215.658\n",
      "[2,  2000] loss: 2177.216\n",
      "[2,  2500] loss: 2185.665\n",
      "[2,  3000] loss: 2173.165\n",
      "[2,  3500] loss: 2194.527\n",
      "[2,  4000] loss: 2188.716\n",
      "[2,  4500] loss: 2218.004\n",
      "[2,  5000] loss: 2177.760\n",
      "[2,  5500] loss: 2158.639\n",
      "[2,  6000] loss: 2189.698\n",
      "[2,  6500] loss: 2196.667\n",
      "[2,  7000] loss: 2156.811\n",
      "[2,  7500] loss: 2233.588\n",
      "[2,  8000] loss: 2183.850\n",
      "[2,  8500] loss: 2166.723\n",
      "[2,  9000] loss: 2153.406\n",
      "[2,  9500] loss: 2189.180\n",
      "[2, 10000] loss: 2123.444\n",
      "[2, 10500] loss: 2160.847\n",
      "[2, 11000] loss: 2173.672\n",
      "[2, 11500] loss: 2144.464\n",
      "[2, 12000] loss: 2129.307\n",
      "[2, 12500] loss: 2159.893\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
